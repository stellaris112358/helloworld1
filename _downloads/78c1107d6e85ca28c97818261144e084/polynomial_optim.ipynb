{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vrNlJmnHIJMt"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://docs.pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2AWITxpIJMv"
      },
      "source": [
        "PyTorch: optim\n",
        "==============\n",
        "\n",
        "A third order polynomial, trained to predict $y=\\sin(x)$ from $-\\pi$ to\n",
        "$\\pi$ by minimizing squared Euclidean distance.\n",
        "\n",
        "This implementation uses the nn package from PyTorch to build the\n",
        "network.\n",
        "\n",
        "Rather than manually updating the weights of the model as we have been\n",
        "doing, we use the optim package to define an Optimizer that will update\n",
        "the weights for us. The optim package defines many optimization\n",
        "algorithms that are commonly used for deep learning, including\n",
        "SGD+momentum, RMSProp, Adam, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrYm_1lVIJMw",
        "outputId": "b525ec2d-6b52-46ff-e295-3b38bc71e275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 44053.05859375\n",
            "199 23541.119140625\n",
            "299 11738.2041015625\n",
            "399 5148.92333984375\n",
            "499 2081.39453125\n",
            "599 1086.286865234375\n",
            "699 874.7413330078125\n",
            "799 772.8781127929688\n",
            "899 655.7171020507812\n",
            "999 530.6312255859375\n",
            "1099 411.5893859863281\n",
            "1199 306.6992492675781\n",
            "1299 218.80564880371094\n",
            "1399 148.18389892578125\n",
            "1499 94.09329986572266\n",
            "1599 55.30048751831055\n",
            "1699 30.11427879333496\n",
            "1799 16.290241241455078\n",
            "1899 10.492270469665527\n",
            "1999 9.022298812866211\n",
            "Result: y = 6.376117411832638e-09 + 0.8442161679267883 x + -1.1338995520304707e-08 x^2 + -0.09116604179143906 x^3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Prepare the input tensor (x, x^2, x^3).\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "# Use the nn package to define our model and loss function.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use RMSprop; the optim package contains many other\n",
        "# optimization algorithms. The first argument to the RMSprop constructor tells the\n",
        "# optimizer which Tensors it should update.\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y by passing x to the model.\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable\n",
        "    # weights of the model). This is because by default, gradients are\n",
        "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "linear_layer = model[0]\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "xx = x.unsqueeze(-1)\n",
        "\n",
        "# Use the nn package to define our model and loss function.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(1, 4),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(4, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use RMSprop; the optim package contains many other\n",
        "# optimization algorithms. The first argument to the RMSprop constructor tells the\n",
        "# optimizer which Tensors it should update.\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y by passing x to the model.\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable\n",
        "    # weights of the model). This is because by default, gradients are\n",
        "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "j1Z4lw9yKk2n",
        "outputId": "c3dd9792-f8c3-4325-cd41-e4a30bc828dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 378.9967346191406\n",
            "199 236.29583740234375\n",
            "299 220.4607696533203\n",
            "399 204.55612182617188\n",
            "499 180.48464965820312\n",
            "599 147.78109741210938\n",
            "699 110.41084289550781\n",
            "799 75.55534362792969\n",
            "899 48.785335540771484\n",
            "999 31.466646194458008\n",
            "1099 22.016956329345703\n",
            "1199 17.04204750061035\n",
            "1299 13.597269058227539\n",
            "1399 10.42985725402832\n",
            "1499 7.673007488250732\n",
            "1599 5.823636531829834\n",
            "1699 4.908355712890625\n",
            "1799 4.549322128295898\n",
            "1899 4.42875862121582\n",
            "1999 4.394473075866699\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}